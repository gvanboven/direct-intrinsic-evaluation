{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import codecs\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import random\n",
    "import copy\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = { \"p1_part1\" : \"..\\\\Test_results\\\\Results_SynDet_part1_participant1.csv\",\n",
    "             \"p1_part2\" : \"..\\\\Test_results\\\\Results_SynDet_part2_participant1.csv\",\n",
    "             \"p2_part1\" : \"..\\\\Test_results\\\\Results_SynDet_part1_participant2.csv\",\n",
    "              \"p2_part2\" : \"..\\\\Test_results\\\\Results_SynDet_part2_participant2.csv\",\n",
    "              \"p3_part1\" : \"..\\\\Test_results\\\\Results_SynDet_part1_participant3.csv\",\n",
    "              \"p3_part2\" : \"..\\\\Test_results\\\\Results_SynDet_part2_participant3.csv\"\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list = []\n",
    "with open(\"..\\\\Test_results\\\\Frequencies.csv\", 'r', encoding=\"utf8\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = \";\")\n",
    "        for line in reader:\n",
    "            freq_list.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_list(file, list_name):\n",
    "    with open(file, 'r', encoding=\"utf8\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = \";\")\n",
    "        count = 0\n",
    "        for n, N2V_additive, N2V_Standard, N2V_Consistency, W2V, SVD_All, SVD_Quine, Non, Rank, Comment in reader:\n",
    "            if count > 0:\n",
    "                list_name.append([int(n), int(N2V_additive), int(N2V_Standard), int(N2V_Consistency), int(W2V), int(SVD_All), int(SVD_Quine), int(Non), int(Rank), Comment])\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p1 = []\n",
    "p2 = []\n",
    "p3 = []\n",
    "for n, (name, file) in enumerate(data_files.items()):\n",
    "    if n < 2: \n",
    "        create_data_list(file, p1)\n",
    "    elif n < 4:\n",
    "        create_data_list(file, p2)\n",
    "    else:\n",
    "        create_data_list(file, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(freq_list)):\n",
    "    p1[n].append(freq_list[n])\n",
    "    p2[n].append(freq_list[n])\n",
    "    p3[n].append(freq_list[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_vector_p1 = []\n",
    "results_vector_p2 = []\n",
    "results_vector_p3 = []\n",
    "for x, row in enumerate(p1):\n",
    "    bool = False\n",
    "    for n, item in enumerate(row):\n",
    "        if 0 < n < 7 and item == 1:\n",
    "            if not bool: \n",
    "                results_vector_p1.append(str(n))\n",
    "            else:\n",
    "                results_vector_p1[x] += str(n)\n",
    "            bool = True\n",
    "        elif n == 7 and not bool :\n",
    "            results_vector_p1.append(str(0))\n",
    "for x, row in enumerate(p2):\n",
    "    bool = False\n",
    "    for n, item in enumerate(row):\n",
    "        if 0 < n < 7 and item == 1:\n",
    "            if not bool: \n",
    "                results_vector_p2.append(str(n))\n",
    "            else:\n",
    "                results_vector_p2[x] += str(n)\n",
    "            bool = True\n",
    "        elif n == 7 and not bool :\n",
    "            results_vector_p2.append(str(0))\n",
    "\n",
    "for x, row in enumerate(p3):\n",
    "    bool = False\n",
    "    for n, item in enumerate(row):\n",
    "        if 0 < n < 7 and item == 1:\n",
    "            if not bool: \n",
    "                results_vector_p3.append(str(n))\n",
    "            else:\n",
    "                results_vector_p3[x] += str(n)\n",
    "            bool = True\n",
    "        elif n == 7 and not bool :\n",
    "            results_vector_p3.append(str(0))\n",
    "\n",
    "#for the calculation of inter rater agreement we can represent the words returned by multiple models \n",
    "#by just one model\n",
    "results_vector_p1 = [x[0] for x in results_vector_p1]\n",
    "results_vector_p2 = [x[0] for x in results_vector_p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists of high and low frequency words per participant\n",
    "p1_high = [model for (n, model) in enumerate(results_vector_p1) if p1[n][-1] == 'high']\n",
    "p1_low = [model for (n, model) in enumerate(results_vector_p1) if p1[n][-1] == 'low']\n",
    "p2_high = [model for (n, model) in enumerate(results_vector_p2) if p2[n][-1] == 'high']\n",
    "p2_low = [model for (n, model) in enumerate(results_vector_p2) if p2[n][-1] == 'low']\n",
    "\n",
    "#lists of high and low rank words per participant\n",
    "p1_rhigh = [model for (n, model) in enumerate(results_vector_p1) if p1[n][-3] == 2]\n",
    "p1_rlow = [model for (n, model) in enumerate(results_vector_p1) if p1[n][-3] == 10]\n",
    "p2_rhigh = [model for (n, model) in enumerate(results_vector_p2) if p2[n][-3] == 2]\n",
    "p2_rlow = [model for (n, model) in enumerate(results_vector_p2) if p2[n][-3] == 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter rater agreement scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter rater agreement as measured by Cohen's kappa between participants:\n",
      "p1 p2 k= 0.48349887856456264\n",
      "p1 p3 k= 0.18570555894929752\n",
      "p2 p3 k= 0.16792144026186573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "print(\"inter rater agreement as measured by Cohen's kappa between participants:\")\n",
    "print(\"p1 p2 k=\", cohen_kappa_score(results_vector_p1, results_vector_p2))\n",
    "print(\"p1 p3 k=\",cohen_kappa_score(results_vector_p1, results_vector_p3))\n",
    "print(\"p2 p3 k=\",cohen_kappa_score(results_vector_p2, results_vector_p3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_probability(ann1_labels, ann2_labels):\n",
    "        zipped = zip(ann1_labels, ann2_labels)\n",
    "        agree = [1 if label[0] == label[1] else 0 for label in zipped]\n",
    "        return sum(agree) / len(agree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint probability high frequency words:  0.5666666666666667\n",
      "joint probability low frequency words:  0.59375\n",
      "high frequency words Cohen's Kappa:  0.4205052005943536\n",
      "low frequency words Cohen's Kappa:  0.5123094958968347\n",
      "\n",
      "joint probability high rank:  0.6129032258064516\n",
      "joint probability low rank:  0.5483870967741935\n",
      "high rank Cohen's Kappa:  0.4545454545454545\n",
      "low rank Cohen's Kappa:  0.44501278772378516\n"
     ]
    }
   ],
   "source": [
    "jb = joint_probability(p1_high, p2_high)\n",
    "print(\"joint probability high frequency words: \", jb)\n",
    "jb = joint_probability(p1_low, p2_low)\n",
    "print(\"joint probability low frequency words: \", jb)\n",
    "ck_high = cohen_kappa_score(p1_high, p2_high)\n",
    "print(\"high frequency words Cohen's Kappa: \", ck_high)\n",
    "ck_low = cohen_kappa_score(p1_low, p2_low)\n",
    "print(\"low frequency words Cohen's Kappa: \", ck_low)\n",
    "print()\n",
    "jb = joint_probability(p1_rhigh, p2_rhigh)\n",
    "print(\"joint probability high rank: \", jb)\n",
    "jb = joint_probability(p1_rlow, p2_rlow)\n",
    "print(\"joint probability low rank: \", jb)\n",
    "ck_rhigh = cohen_kappa_score(p1_rhigh, p2_rhigh)\n",
    "print(\"high rank Cohen's Kappa: \", ck_rhigh)\n",
    "ck_rlow = cohen_kappa_score(p1_rlow, p2_rlow)\n",
    "print(\"low rank Cohen's Kappa: \", ck_rlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_nozero(ann1, ann2):\n",
    "    zipped = zip(ann1, ann2)\n",
    "    agree = []\n",
    "    for n, label in enumerate(zipped):\n",
    "        if label [0] != '0' and label[1] != '0':\n",
    "            if label[0] == label[1]:\n",
    "                agree.append(1)\n",
    "            else:\n",
    "                agree.append(0)\n",
    "    return sum(agree) / len(agree)\n",
    "\n",
    "def joint_zero(ann1, ann2):\n",
    "        zipped = zip(ann1, ann2)\n",
    "        agree = []\n",
    "        for label in zipped:\n",
    "            if label[0] == '0' or label[1] == '0':\n",
    "                if label[0] == label[1]:\n",
    "                    agree.append(1)\n",
    "                else:\n",
    "                    agree.append(0)\n",
    "        return sum(agree) / len(agree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general joint probability :  0.5806451612903226\n",
      "joint probability for the none option: 0.2727272727272727\n",
      "joint probability for the not-none option: 0.75\n",
      "\n",
      "general Cohen's Kappa:  0.48349887856456264\n",
      "Cohen's Kappa for the none option:  -0.11041009463722395\n",
      "Cohen's Kappa for the not-none option:  0.6566523605150214\n"
     ]
    }
   ],
   "source": [
    "jb = joint_probability(results_vector_p1, results_vector_p2)#df, 1,2)\n",
    "print(\"general joint probability : \", jb)\n",
    "jb = joint_zero(results_vector_p1, results_vector_p2)\n",
    "print(\"joint probability for the none option:\", jb)\n",
    "jb = joint_nozero(results_vector_p1, results_vector_p2)\n",
    "print(\"joint probability for the not-none option:\", jb)\n",
    "print()\n",
    "zipped = zip(results_vector_p1, results_vector_p2)\n",
    "zero_1, zero_2 = [], []\n",
    "no_zero_1, no_zero_2 = [], []\n",
    "for label in zipped:\n",
    "    if label[0] == '0' or label[1] == '0':\n",
    "        zero_1.append(label[0])\n",
    "        zero_2.append(label[1])\n",
    "    else:\n",
    "        no_zero_1.append(label[0])\n",
    "        no_zero_2.append(label[1])\n",
    "ck_general = cohen_kappa_score(results_vector_p1, results_vector_p2)\n",
    "print(\"general Cohen's Kappa: \", ck_general)\n",
    "ck_zero = cohen_kappa_score(zero_1, zero_2)\n",
    "print(\"Cohen's Kappa for the none option: \", ck_zero)\n",
    "ck_no_zero = cohen_kappa_score(no_zero_1, no_zero_2)\n",
    "print(\"Cohen's Kappa for the not-none option: \", ck_no_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most and least agreed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>freq</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>high</td>\n",
       "      <td>objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "      <td>memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "      <td>intensional_abstraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>intensional_abstraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "      <td>description</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  p1  p2  freq                     word\n",
       "0           0   6   6  high                  objects\n",
       "1           1   3   3   low                   memory\n",
       "2           2   0   3   low  intensional_abstraction\n",
       "3           3   4   4   low  intensional_abstraction\n",
       "4           4  12   0  high              description"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ia_path = '..\\\\Test_results\\\\syn_det_results-word-freqs.csv'\n",
    "ia_df = pd.read_csv(ia_path, sep=';')\n",
    "ia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word that was agreed upon each time:\n",
      "2 paradox\n",
      "2 nouns\n",
      "2 subtraction\n",
      "2 truth_vehicles\n",
      "2 nouns\n",
      "2 intension\n",
      "2 subtraction\n",
      "2 mental_states\n",
      "2 utterances\n",
      "2 paradox\n",
      "2 mental_states\n",
      "2 intension\n",
      "2 object\n",
      "2 object\n",
      "2 quantification\n",
      "2 quantification\n",
      "2 information\n",
      "2 utterances\n",
      "2 information\n",
      "2 truth_vehicles\n"
     ]
    }
   ],
   "source": [
    "agreed_words = list(ia_df[ia_df['p1'] ==ia_df['p2']]['word'].values)\n",
    "print(\"Word that was agreed upon each time:\")\n",
    "for word in agreed_words:\n",
    "    #each word is tested on two ranks, so two agreements is the maximum\n",
    "    if agreed_words.count(word) == 2:\n",
    "        print(agreed_words.count(word), word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word that was disagreed upon each time:\n",
      "2 attributes\n",
      "2 application\n",
      "2 application\n",
      "2 transparency\n",
      "2 adjectives\n",
      "2 attributes\n",
      "2 logical_particles\n",
      "2 adjectives\n",
      "2 transparency\n",
      "2 logical_particles\n"
     ]
    }
   ],
   "source": [
    "disagreed_words = list(ia_df[ia_df['p1'] !=ia_df['p2']]['word'].values)\n",
    "print(\"Word that was disagreed upon each time:\")\n",
    "for word in disagreed_words:\n",
    "    #each word is tested on two ranks, so two disagreements is the maximum\n",
    "    if disagreed_words.count(word) == 2:\n",
    "        print(disagreed_words.count(word), word)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
